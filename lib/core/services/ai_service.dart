import 'dart:convert';
import 'package:http/http.dart' as http;
import 'package:flutter/foundation.dart';
import 'ai_config.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';

class AIService {
  static const String _huggingFaceBaseUrl =
      'https://api-inference.huggingface.co/models';
  static const String _googleAIBaseUrl =
      'https://generativelanguage.googleapis.com/v1/models';

  /// Gera conte√∫do markdown usando Google AI (gratuito) ou Hugging Face
  static Future<String> generateMarkdownContent(String prompt,
      {String? model, required WidgetRef ref}) async {
    try {
      debugPrint('ü§ñ Tentando Google AI...');
      return await _generateWithGoogleAI(prompt, ref);
    } catch (e) {
      debugPrint('‚ùå Google AI falhou: $e');
      final huggingFaceToken = AIConfig.getHuggingFaceToken(ref);
      if (huggingFaceToken.isNotEmpty) {
        try {
          debugPrint('ü§ñ Tentando Hugging Face...');
          return await _generateWithHuggingFace(prompt, model, ref);
        } catch (e) {
          debugPrint('‚ùå Hugging Face falhou: $e');
          return _generateFallbackContent(prompt);
        }
      } else {
        return _generateFallbackContent(prompt);
      }
    }
  }

  /// ‚úÖ CORRIGIDO: Google AI sem thinkingConfig
  static Future<String> _generateWithGoogleAI(
      String prompt, WidgetRef ref) async {
    final token = AIConfig.getGoogleAIToken(ref);
    if (token.isEmpty) {
      throw Exception(
          'Token do Google AI n√£o configurado. Configure em Settings > Configura√ß√µes de IA');
    }

    final uri = Uri.parse(
        '$_googleAIBaseUrl/gemini-2.5-flash:generateContent?key=$token');

    final response = await http.post(
      uri,
      headers: {
        'Content-Type': 'application/json',
      },
      body: jsonEncode({
        'contents': [
          {
            'parts': [
              {
                'text':
                    'Gere conte√∫do markdown bem estruturado sobre: $prompt\n\n'
                        'Requisitos:\n'
                        '- Use t√≠tulos e subt√≠tulos apropriados (# ## ###)\n'
                        '- Inclua listas com marcadores quando relevante\n'
                        '- Use **negrito** para destacar pontos importantes\n'
                        '- Inclua *it√°lico* para √™nfase\n'
                        '- Mantenha a formata√ß√£o limpa e profissional\n'
                        '- Responda em portugu√™s brasileiro\n\n'
                        'Responda apenas com o conte√∫do markdown:'
              }
            ]
          }
        ],
        'generationConfig': {
          'temperature': 0.7,
          'topK': 40,
          'topP': 0.95,
          'maxOutputTokens': 2048,
          'candidateCount': 1,
          'stopSequences': []
        }
      }),
    );

    if (response.statusCode == 200) {
      final data = jsonDecode(response.body);

      if (data['candidates'] != null && data['candidates'].isNotEmpty) {
        final generatedText =
            data['candidates'][0]['content']['parts'][0]['text'];
        return _ensureMarkdownFormat(generatedText);
      } else {
        throw Exception('Resposta vazia da Google AI');
      }
    } else {
      throw Exception(
          'Erro na Google AI: ${response.statusCode} - ${response.body}');
    }
  }

  /// ‚úÖ CORRIGIDO: Hugging Face sem recurs√£o infinita
  static Future<String> _generateWithHuggingFace(
      String prompt, String? model, WidgetRef ref) async {
    final selectedModel = model ?? AIConfig.defaultModel;
    final token = AIConfig.getHuggingFaceToken(ref);

    if (token.isEmpty) {
      throw Exception('Token do Hugging Face n√£o configurado');
    }

    // Lista de modelos para tentar
    final modelsToTry = [
      selectedModel,
      ...AIConfig.alternativeModels.where((m) => m != selectedModel)
    ];

    for (int i = 0; i < modelsToTry.length; i++) {
      final currentModel = modelsToTry[i];

      try {
        debugPrint(
            'ü§ñ Tentando modelo: $currentModel (${i + 1}/${modelsToTry.length})');

        final uri = Uri.parse('$_huggingFaceBaseUrl/$currentModel');
        final response = await http.post(
          uri,
          headers: {
            'Content-Type': 'application/json',
            'Authorization': 'Bearer $token',
          },
          body: jsonEncode({
            'inputs': _buildHuggingFacePrompt(prompt),
            'parameters': {
              'max_length': 1024,
              'temperature': 0.7,
              'do_sample': true,
              'top_p': 0.9,
              'repetition_penalty': 1.1,
              'return_full_text': false,
            },
            'options': {
              'wait_for_model': true,
              'use_cache': false,
            }
          }),
        );

        if (response.statusCode == 200) {
          final result = _extractGeneratedText(response.body);
          if (result.isNotEmpty) {
            debugPrint('‚úÖ Sucesso com modelo: $currentModel');
            return result;
          }
        } else if (response.statusCode == 401) {
          throw Exception(
              'Token inv√°lido. Verifique seu token do Hugging Face');
        } else {
          debugPrint('‚ö†Ô∏è Modelo $currentModel falhou: ${response.statusCode}');
          continue; // Tenta pr√≥ximo modelo
        }
      } catch (e) {
        debugPrint('‚ùå Erro com modelo $currentModel: $e');
        if (i == modelsToTry.length - 1) {
          // √öltimo modelo, lan√ßa exce√ß√£o
          throw Exception('Todos os modelos do Hugging Face falharam');
        }
        continue; // Tenta pr√≥ximo modelo
      }
    }

    throw Exception('Todos os modelos do Hugging Face falharam');
  }

  /// Constr√≥i prompt otimizado para Hugging Face
  static String _buildHuggingFacePrompt(String prompt) {
    return '''
T√≥pico: $prompt

Crie um documento markdown estruturado com:
- T√≠tulo principal
- Subt√≠tulos
- Listas com marcadores
- Texto formatado

Documento:
''';
  }

  /// ‚úÖ CORRIGIDO: Extra√ß√£o de texto melhorada
  static String _extractGeneratedText(String responseBody) {
    try {
      final data = jsonDecode(responseBody);
      String generatedText = '';

      if (data is List && data.isNotEmpty) {
        generatedText = data.first['generated_text'] ?? '';
      } else if (data is Map && data.containsKey('generated_text')) {
        generatedText = data['generated_text'] ?? '';
      } else {
        throw Exception('Formato de resposta inv√°lido');
      }

      // Remove o prompt original se presente
      final cleanText = _removeOriginalPrompt(generatedText);
      return _ensureMarkdownFormat(cleanText);
    } catch (e) {
      debugPrint('‚ùå Erro ao processar resposta: $e');
      rethrow;
    }
  }

  /// Remove prompt original da resposta
  static String _removeOriginalPrompt(String generatedText) {
    final lines = generatedText.split('\n');

    // Remove linhas que parecem ser o prompt original
    final filteredLines = lines.where((line) {
      final trimmed = line.trim();
      return !trimmed.startsWith('T√≥pico:') &&
          !trimmed.startsWith('Crie um documento') &&
          !trimmed.startsWith('Documento:') &&
          trimmed.isNotEmpty;
    }).toList();

    return filteredLines.join('\n').trim();
  }

  /// Garante formato markdown adequado
  static String _ensureMarkdownFormat(String text) {
    if (text.isEmpty) {
      return '# Conte√∫do\n\nNenhum conte√∫do foi gerado.';
    }

    String cleaned = text.trim();

    // Garante quebras de linha adequadas
    cleaned = cleaned.replaceAll(RegExp(r'\n{3,}'), '\n\n');

    return cleaned;
  }

  /// ‚úÖ NOVO: Conte√∫do de fallback quando todas as APIs falham
  static String _generateFallbackContent(String prompt) {
    return '''
# üìÑ $prompt

## Vis√£o Geral
Este documento foi gerado automaticamente sobre o tema: **$prompt**.

## Estrutura Sugerida
- **Introdu√ß√£o**: Apresenta√ß√£o do tema
- **Desenvolvimento**: Pontos principais
- **Detalhes**: Informa√ß√µes espec√≠ficas
- **Conclus√£o**: Resumo final

## Nota
*Para obter conte√∫do personalizado, verifique:*
- Conex√£o com a internet
- Configura√ß√£o das chaves de API
- Disponibilidade dos servi√ßos

---
*Conte√∫do gerado como fallback*
''';
  }

  /// Verifica disponibilidade dos servi√ßos
  static Future<bool> isAvailable(WidgetRef ref) async {
    // Testa Google AI primeiro
    try {
      final token = AIConfig.getGoogleAIToken(ref);
      if (token.isNotEmpty) {
        final response = await http.get(
          Uri.parse('$_googleAIBaseUrl/gemini-2.5-flash?key=$token'),
        );
        if (response.statusCode == 200) {
          return true;
        }
      }
    } catch (e) {
      debugPrint('Google AI n√£o dispon√≠vel: $e');
    }

    // Testa Hugging Face como fallback
    try {
      final token = AIConfig.getHuggingFaceToken(ref);
      if (token.isNotEmpty) {
        final response = await http.get(
          Uri.parse('$_huggingFaceBaseUrl/${AIConfig.defaultModel}'),
          headers: {'Authorization': 'Bearer $token'},
        );
        return response.statusCode == 200;
      }
    } catch (e) {
      debugPrint('Hugging Face n√£o dispon√≠vel: $e');
    }

    return false;
  }
}
